{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Realtime inference with AWS DeepLens\n",
    "\n",
    "This accompanies my article on Medium. I don't know the final URL of that draft yet, but you should be able to find it via https://medium.com/@tomgrek.\n",
    "\n",
    "To run this you will need to grab the pretrained model:\n",
    "```\n",
    "wget https://storage.googleapis.com/download.tensorflow.org/models/inception_v3_2016_08_28_frozen.pb.tar.gz\n",
    "tar -xvzf inception_v3_2016_08_28_frozen.pb.tar.gz\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "graph_def = tf.GraphDef()\n",
    "with open('./inception_v3_2016_08_28_frozen.pb', \"rb\") as f:\n",
    "    graph_def.ParseFromString(f.read())\n",
    "with graph.as_default():\n",
    "    tf.import_graph_def(graph_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(label_file):\n",
    "  label = []\n",
    "  proto_as_ascii_lines = tf.gfile.GFile(label_file).readlines()\n",
    "  for l in proto_as_ascii_lines:\n",
    "    label.append(l.rstrip())\n",
    "  return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = \"input\"\n",
    "output_layer = \"InceptionV3/Predictions/Reshape_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_name = \"import/\" + input_layer\n",
    "output_name = \"import/\" + output_layer\n",
    "input_operation = graph.get_operation_by_name(input_name)\n",
    "output_operation = graph.get_operation_by_name(output_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import awscam\n",
    "import cv2\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('monitor', 0.28125063)\n",
      "('screen', 0.15084484)\n",
      "('television', 0.12388436)\n",
      "('water jug', 0.09155932)\n",
      "('beer glass', 0.04396197)\n",
      "('monitor', 0.22072905)\n",
      "('water jug', 0.14242181)\n",
      "('television', 0.12632273)\n",
      "('screen', 0.10927667)\n",
      "('beer glass', 0.066972956)\n",
      "('monitor', 0.27544972)\n",
      "('water jug', 0.12971021)\n",
      "('screen', 0.12900297)\n",
      "('television', 0.101049915)\n",
      "('beer glass', 0.059571203)\n",
      "('monitor', 0.21874452)\n",
      "('water jug', 0.15469997)\n",
      "('screen', 0.12310624)\n",
      "('television', 0.0992532)\n",
      "('beer glass', 0.060115915)\n",
      "('monitor', 0.29284143)\n",
      "('screen', 0.14606945)\n",
      "('television', 0.11821335)\n",
      "('beer glass', 0.073011056)\n",
      "('water jug', 0.036694065)\n",
      "('running shoe', 0.078758344)\n",
      "('hand blower', 0.05470746)\n",
      "('sandal', 0.036435798)\n",
      "('electric fan', 0.033989843)\n",
      "('bassinet', 0.019181341)\n",
      "('crash helmet', 0.16109857)\n",
      "('seat belt', 0.10279817)\n",
      "('bucket', 0.06464464)\n",
      "('toilet seat', 0.04851903)\n",
      "('oxygen mask', 0.025366016)\n",
      "('toilet seat', 0.17103137)\n",
      "('crash helmet', 0.07273375)\n",
      "('toilet tissue', 0.06422536)\n",
      "('seat belt', 0.054481633)\n",
      "('plunger', 0.04648115)\n",
      "('washbasin', 0.13950598)\n",
      "('soap dispenser', 0.110169716)\n",
      "('toilet seat', 0.10201469)\n",
      "('bathtub', 0.06303269)\n",
      "('toilet tissue', 0.028918497)\n",
      "('greenhouse', 0.057053868)\n",
      "('washer', 0.056520432)\n",
      "('coil', 0.050935525)\n",
      "('bathtub', 0.050078575)\n",
      "('tub', 0.03053016)\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,10):\n",
    "    got, frame = awscam.getLastFrame()\n",
    "    cv2.imwrite('output.jpg', frame)\n",
    "    image_reader = tf.image.decode_jpeg(tf.read_file('./output.jpg', \"file_reader\"), channels=3, name=\"jpeg_reader\")\n",
    "    float_caster = tf.cast(image_reader, tf.float32)\n",
    "    dims_expander = tf.expand_dims(float_caster, 0)\n",
    "    resized = tf.image.resize_bilinear(dims_expander, [299, 299])\n",
    "    normalized = tf.divide(tf.subtract(resized, [0]), [255])\n",
    "    sess = tf.Session()\n",
    "    image = sess.run(normalized)\n",
    "    with tf.Session(graph=graph) as sess:\n",
    "        results = sess.run(output_operation.outputs[0], {\n",
    "            input_operation.outputs[0]: image\n",
    "        })\n",
    "    results = np.squeeze(results)\n",
    "    top_k = results.argsort()[-5:][::-1]\n",
    "    labels = load_labels(\"imagenet_slim_labels.txt\")\n",
    "    for i in top_k:\n",
    "        print(labels[i], results[i])\n",
    "    time.sleep(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
